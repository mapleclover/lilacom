{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# YOLOv8 í–‰ì‚¬ ë°°ì¹˜ë„ ê°ì²´ ì¸ì‹ - ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤ìŠµ\n\nì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” YOLOv8ì„ ì‚¬ìš©í•˜ì—¬ í–‰ì‚¬ ë°°ì¹˜ë„ ì´ë¯¸ì§€ì—ì„œ ê°ì²´ë¥¼ ì¸ì‹í•˜ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n\n## í•™ìŠµ ëª©í‘œ\n1. YOLOv8 í™˜ê²½ì„ ì„¤ì •í•˜ê³  í•„ìˆ˜ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n2. í–‰ì‚¬ ë°°ì¹˜ë„ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¼ë²¨ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n3. ì»¤ìŠ¤í…€ YOLOv8 ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n4. í•™ìŠµëœ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ë°°ì¹˜ë„ë¥¼ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n5. ê°ì²´ ì¸ì‹ ê²°ê³¼ë¥¼ ì•ˆì „ ë¶„ì„ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n\n## ëŒ€ìƒ í´ë˜ìŠ¤ (8ê°œ)\n\n| ID | ì˜ë¬¸ëª… | í•œê¸€ëª… | ì„¤ëª… |\n|----|--------|--------|------|\n| 0 | booth | ë¶€ìŠ¤ | ì „ì‹œ/íŒë§¤ ë¶€ìŠ¤ |\n| 1 | stage | ë¬´ëŒ€ | ê³µì—°/í–‰ì‚¬ ë¬´ëŒ€ |\n| 2 | exit | ì¶œêµ¬ | ë¹„ìƒêµ¬/ì¼ë°˜ ì¶œêµ¬ |\n| 3 | entrance | ì…êµ¬ | ë©”ì¸/ë³´ì¡° ì…êµ¬ |\n| 4 | restroom | í™”ì¥ì‹¤ | í™”ì¥ì‹¤ ì‹œì„¤ |\n| 5 | food_area | ìŒì‹êµ¬ì—­ | í‘¸ë“œì½”íŠ¸/ìŒì‹ì  |\n| 6 | seating | ì¢Œì„êµ¬ì—­ | ê°ì„/íœ´ê²Œê³µê°„ |\n| 7 | boundary | ê²½ê³„ì„  | í–‰ì‚¬ì¥ ì „ì²´ ê²½ê³„ì„  |\n\n> **í†µë¡œ**: boundary ë‚´ë¶€ì—ì„œ ìœ„ í´ë˜ìŠ¤(0~6)ë¥¼ ì œì™¸í•œ ì˜ì—­ì´ ìë™ìœ¼ë¡œ í†µë¡œë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.\n\n## ì „ì²´ íŒŒì´í”„ë¼ì¸\n```\në°ì´í„° ìˆ˜ì§‘ â†’ ë¼ë²¨ë§ â†’ ë°ì´í„°ì…‹ êµ¬ì„± â†’ ëª¨ë¸ í•™ìŠµ â†’ ê²€ì¦ â†’ ì¶”ë¡  â†’ í†µë¡œ ìë™ ê³„ì‚° â†’ ì•ˆì „ ë¶„ì„\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜\n\nYOLOv8 ì‹¤ìŠµì— í•„ìš”í•œ ëª¨ë“  íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤. GPUê°€ ìˆìœ¼ë©´ CUDA ì§€ì› PyTorchë¥¼ ì„¤ì¹˜í•˜ì—¬ í•™ìŠµ ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T12:27:56.325271Z",
     "start_time": "2025-11-25T12:27:49.996055Z"
    }
   },
   "source": [
    "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"YOLOv8 ì‹¤ìŠµì— í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\"\"\"\n",
    "    packages = [\n",
    "        'ultralytics',      # YOLOv8\n",
    "        'opencv-python',    # ì´ë¯¸ì§€ ì²˜ë¦¬\n",
    "        'torch',            # PyTorch\n",
    "        'torchvision',      # ì´ë¯¸ì§€ ë³€í™˜\n",
    "        'matplotlib',       # ì‹œê°í™”\n",
    "        'pandas',           # ë°ì´í„° ë¶„ì„\n",
    "        'numpy',            # ìˆ˜ì¹˜ ì—°ì‚°\n",
    "        'pillow',           # ì´ë¯¸ì§€ ì²˜ë¦¬\n",
    "        'pyyaml',           # YAML íŒŒì¼ ì²˜ë¦¬\n",
    "        'tqdm',             # ì§„í–‰ë¥  í‘œì‹œ\n",
    "        'seaborn',          # í†µê³„ ì‹œê°í™”\n",
    "        'labelImg',         # ë¼ë²¨ë§ ë„êµ¬\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
    "    \n",
    "    print(\"\\nâœ… ëª¨ë“  íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\")\n",
    "\n",
    "# íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì²˜ìŒ ì‹¤í–‰ ì‹œ ì£¼ì„ í•´ì œ)\n",
    "install_packages()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing ultralytics...\n",
      "Installing opencv-python...\n",
      "Installing torch...\n",
      "Installing torchvision...\n",
      "Installing matplotlib...\n",
      "Installing pandas...\n",
      "Installing numpy...\n",
      "Installing pillow...\n",
      "Installing pyyaml...\n",
      "Installing tqdm...\n",
      "Installing seaborn...\n",
      "Installing labelImg...\n",
      "\n",
      "âœ… ëª¨ë“  íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T12:27:58.304479Z",
     "start_time": "2025-11-25T12:27:58.301985Z"
    }
   },
   "source": "# GPU PyTorch ì„¤ì¹˜ ì•ˆë‚´ (ì„ íƒì‚¬í•­)\n# NVIDIA GPUê°€ ìˆëŠ” ê²½ìš° ì•„ë˜ ëª…ë ¹ì–´ë¡œ CUDA ì§€ì› PyTorch ì„¤ì¹˜\n\n# CUDA 11.8:\n# pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n\n# CUDA 12.1:\n# pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n\n# Apple Silicon (M1/M2/M3):\n# pip install torch torchvision  # MPS ìë™ ì§€ì›\n\nprint(\"GPU PyTorch ì„¤ì¹˜ê°€ í•„ìš”í•œ ê²½ìš° ìœ„ ì£¼ì„ì˜ ëª…ë ¹ì–´ë¥¼ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU PyTorch ì„¤ì¹˜ê°€ í•„ìš”í•œ ê²½ìš° ìœ„ ì£¼ì„ì˜ ëª…ë ¹ì–´ë¥¼ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° í™˜ê²½ í™•ì¸"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T12:56:39.081159Z",
     "start_time": "2025-11-25T12:56:39.073603Z"
    }
   },
   "source": "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\nimport os\nimport sys\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport yaml\nimport json\nimport shutil\nimport random\nfrom pathlib import Path\nfrom datetime import datetime\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom ultralytics import YOLO\nimport torch\n\n# ì‹œê°í™” ì„¤ì • (í•œê¸€ í°íŠ¸)\nplt.rcParams['font.family'] = 'AppleGothic'  # macOS\n# plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows\nplt.rcParams['axes.unicode_minus'] = False\nplt.rcParams['figure.figsize'] = (12, 8)\n\nprint(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T12:56:41.472334Z",
     "start_time": "2025-11-25T12:56:41.465961Z"
    }
   },
   "source": "# ì‹¤í–‰ í™˜ê²½ ì •ë³´ í™•ì¸\nprint(\"=\" * 50)\nprint(\"ì‹¤í–‰ í™˜ê²½ ì •ë³´\")\nprint(\"=\" * 50)\nprint(f\"Python ë²„ì „: {sys.version}\")\nprint(f\"PyTorch ë²„ì „: {torch.__version__}\")\nprint(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n\nif torch.cuda.is_available():\n    print(f\"CUDA ë²„ì „: {torch.version.cuda}\")\n    print(f\"GPU ì´ë¦„: {torch.cuda.get_device_name(0)}\")\nelif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n    print(\"Apple MPS ê°€ì† ì‚¬ìš© ê°€ëŠ¥\")\n\n# ë””ë°”ì´ìŠ¤ ì„¤ì •\nif torch.cuda.is_available():\n    device = 'cuda'\nelif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n    device = 'mps'\nelse:\n    device = 'cpu'\n\nprint(f\"\\nğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ì‹¤í–‰ í™˜ê²½ ì •ë³´\n",
      "==================================================\n",
      "Python ë²„ì „: 3.9.6 (default, Oct 17 2025, 17:15:53) \n",
      "[Clang 17.0.0 (clang-1700.4.4.1)]\n",
      "PyTorch ë²„ì „: 2.8.0\n",
      "CUDA ì‚¬ìš© ê°€ëŠ¥: False\n",
      "Apple MPS ê°€ì† ì‚¬ìš© ê°€ëŠ¥\n",
      "\n",
      "ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: mps\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±\n\nYOLOv8 í•™ìŠµì— í•„ìš”í•œ í‘œì¤€ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n\n```\nproject_root/\nâ”œâ”€â”€ data/\nâ”‚   â”œâ”€â”€ images/\nâ”‚   â”‚   â”œâ”€â”€ train/     # í•™ìŠµìš© ì´ë¯¸ì§€ (80%)\nâ”‚   â”‚   â”œâ”€â”€ val/       # ê²€ì¦ìš© ì´ë¯¸ì§€ (10%)\nâ”‚   â”‚   â””â”€â”€ test/      # í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ (10%)\nâ”‚   â””â”€â”€ labels/\nâ”‚       â”œâ”€â”€ train/     # í•™ìŠµìš© ë¼ë²¨\nâ”‚       â”œâ”€â”€ val/       # ê²€ì¦ìš© ë¼ë²¨\nâ”‚       â””â”€â”€ test/      # í…ŒìŠ¤íŠ¸ìš© ë¼ë²¨\nâ”œâ”€â”€ models/            # í•™ìŠµëœ ëª¨ë¸ ì €ì¥\nâ”œâ”€â”€ results/           # ì¶”ë¡  ê²°ê³¼ ì €ì¥\nâ”œâ”€â”€ configs/           # ì„¤ì • íŒŒì¼\nâ””â”€â”€ samples/           # ì›ë³¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ\n```"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T13:17:31.137802Z",
     "start_time": "2025-11-25T13:17:31.130413Z"
    }
   },
   "source": "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì •ì˜\nPROJECT_ROOT = Path.cwd()\nDATA_DIR = PROJECT_ROOT / 'data'\nIMAGES_DIR = DATA_DIR / 'images'\nLABELS_DIR = DATA_DIR / 'labels'\nMODELS_DIR = PROJECT_ROOT / 'models'\nRESULTS_DIR = PROJECT_ROOT / 'results'\nCONFIGS_DIR = PROJECT_ROOT / 'configs'\nSAMPLES_DIR = PROJECT_ROOT / 'samples'\n\n# í•˜ìœ„ ê²½ë¡œ ì •ì˜\nTRAIN_IMAGES = IMAGES_DIR / 'train'\nVAL_IMAGES = IMAGES_DIR / 'val'\nTEST_IMAGES = IMAGES_DIR / 'test'\nTRAIN_LABELS = LABELS_DIR / 'train'\nVAL_LABELS = LABELS_DIR / 'val'\nTEST_LABELS = LABELS_DIR / 'test'\n\nprint(f\"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í”„ë¡œì íŠ¸ ë£¨íŠ¸: /Users/youeuncheol/PyCharmMiscProject\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T13:17:33.519488Z",
     "start_time": "2025-11-25T13:17:33.515128Z"
    }
   },
   "source": "# ë””ë ‰í† ë¦¬ ìƒì„±\ndirectories = [\n    TRAIN_IMAGES, VAL_IMAGES, TEST_IMAGES,\n    TRAIN_LABELS, VAL_LABELS, TEST_LABELS,\n    MODELS_DIR, RESULTS_DIR, CONFIGS_DIR, SAMPLES_DIR\n]\n\nfor dir_path in directories:\n    dir_path.mkdir(parents=True, exist_ok=True)\n    print(f\"âœ“ {dir_path.relative_to(PROJECT_ROOT)}\")\n\nprint(\"\\nâœ… ëª¨ë“  ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ!\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ data/images/train\n",
      "âœ“ data/images/val\n",
      "âœ“ data/images/test\n",
      "âœ“ data/labels/train\n",
      "âœ“ data/labels/val\n",
      "âœ“ data/labels/test\n",
      "âœ“ models\n",
      "âœ“ results\n",
      "âœ“ configs\n",
      "âœ“ samples\n",
      "\n",
      "âœ… ëª¨ë“  ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ!\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. í´ë˜ìŠ¤ ì •ì˜ ë° ë°ì´í„°ì…‹ ì„¤ì •\n\ní–‰ì‚¬ ë°°ì¹˜ë„ ë¶„ì„ì„ ìœ„í•œ 8ê°œ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•˜ê³ , YOLOv8 í•™ìŠµì— í•„ìš”í•œ YAML ì„¤ì • íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T13:17:41.740209Z",
     "start_time": "2025-11-25T13:17:41.733306Z"
    }
   },
   "source": "# í´ë˜ìŠ¤ ì •ì˜\nCLASS_NAMES = [\n    'booth',       # 0: ë¶€ìŠ¤\n    'stage',       # 1: ë¬´ëŒ€\n    'exit',        # 2: ì¶œêµ¬\n    'entrance',    # 3: ì…êµ¬\n    'restroom',    # 4: í™”ì¥ì‹¤\n    'food_area',   # 5: ìŒì‹êµ¬ì—­\n    'seating',     # 6: ì¢Œì„êµ¬ì—­\n    'boundary',    # 7: ê²½ê³„ì„ \n]\n\n# í•œê¸€ëª… ë§¤í•‘\nCLASS_NAMES_KR = {\n    'booth': 'ë¶€ìŠ¤',\n    'stage': 'ë¬´ëŒ€',\n    'exit': 'ì¶œêµ¬',\n    'entrance': 'ì…êµ¬',\n    'restroom': 'í™”ì¥ì‹¤',\n    'food_area': 'ìŒì‹êµ¬ì—­',\n    'seating': 'ì¢Œì„êµ¬ì—­',\n    'boundary': 'ê²½ê³„ì„ ',\n}\n\n# ì‹œê°í™”ìš© ìƒ‰ìƒ (BGR)\nCLASS_COLORS = {\n    'booth': (0, 165, 255),      # ì£¼í™©\n    'stage': (0, 0, 255),        # ë¹¨ê°•\n    'exit': (0, 255, 0),         # ì´ˆë¡\n    'entrance': (255, 255, 0),   # ì²­ë¡\n    'restroom': (255, 0, 255),   # ë§ˆì  íƒ€\n    'food_area': (19, 69, 139),  # ê°ˆìƒ‰\n    'seating': (128, 128, 128),  # íšŒìƒ‰\n    'boundary': (0, 255, 255),   # ë…¸ë‘\n}\n\n# í†µë¡œ ì‹œê°í™” ìƒ‰ìƒ (ìë™ ê³„ì‚°ìš©)\nPATHWAY_COLOR = (255, 0, 0)  # íŒŒë€ìƒ‰ (BGR)\n\nprint(f\"ì´ {len(CLASS_NAMES)}ê°œ í´ë˜ìŠ¤ ì •ì˜ë¨\")\nfor idx, name in enumerate(CLASS_NAMES):\n    print(f\"  {idx}: {name} ({CLASS_NAMES_KR[name]})\")\nprint(f\"\\nâ€» í†µë¡œëŠ” boundary ë‚´ë¶€ì—ì„œ ìë™ ê³„ì‚°ë©ë‹ˆë‹¤.\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ 8ê°œ í´ë˜ìŠ¤ ì •ì˜ë¨\n",
      "  0: booth (ë¶€ìŠ¤)\n",
      "  1: stage (ë¬´ëŒ€)\n",
      "  2: exit (ì¶œêµ¬)\n",
      "  3: entrance (ì…êµ¬)\n",
      "  4: restroom (í™”ì¥ì‹¤)\n",
      "  5: food_area (ìŒì‹êµ¬ì—­)\n",
      "  6: seating (ì¢Œì„êµ¬ì—­)\n",
      "  7: boundary (ê²½ê³„ì„ )\n",
      "\n",
      "â€» í†µë¡œëŠ” boundary ë‚´ë¶€ì—ì„œ ìë™ ê³„ì‚°ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T13:17:45.928953Z",
     "start_time": "2025-11-25T13:17:45.922446Z"
    }
   },
   "source": "# YOLOv8 ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ (YAML) ìƒì„±\ndataset_config = {\n    'path': str(DATA_DIR.absolute()),\n    'train': 'images/train',\n    'val': 'images/val',\n    'test': 'images/test',\n    'nc': len(CLASS_NAMES),\n    'names': CLASS_NAMES,\n}\n\nyaml_path = CONFIGS_DIR / 'event_layout.yaml'\nwith open(yaml_path, 'w', encoding='utf-8') as f:\n    yaml.dump(dataset_config, f, default_flow_style=False, allow_unicode=True)\n\nprint(f\"âœ… ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ ìƒì„±: {yaml_path}\")\nprint(\"\\níŒŒì¼ ë‚´ìš©:\")\nprint(\"-\" * 40)\nwith open(yaml_path, 'r') as f:\n    print(f.read())",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ ìƒì„±: /Users/youeuncheol/PyCharmMiscProject/configs/event_layout.yaml\n",
      "\n",
      "íŒŒì¼ ë‚´ìš©:\n",
      "----------------------------------------\n",
      "names:\n",
      "- booth\n",
      "- stage\n",
      "- exit\n",
      "- entrance\n",
      "- restroom\n",
      "- food_area\n",
      "- seating\n",
      "- boundary\n",
      "nc: 8\n",
      "path: /Users/youeuncheol/PyCharmMiscProject/data\n",
      "test: images/test\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. ë°ì´í„° ì¤€ë¹„ ë° ì´ë¯¸ì§€ ì—…ë¡œë“œ\n\n### ì´ë¯¸ì§€ ìˆ˜ì§‘ ì§€ì¹¨\n1. **ì´ë¯¸ì§€ ì†ŒìŠ¤**: ì‹¤ì œ í–‰ì‚¬ ë°°ì¹˜ë„, CAD ë„ë©´, ë””ì§€í„¸ ë°°ì¹˜ë„\n2. **ìš”êµ¬ì‚¬í•­**: JPG/PNG, ìµœì†Œ 640x640, 10MB ì´í•˜\n3. **ê¶Œì¥ ìˆ˜ëŸ‰**: í´ë˜ìŠ¤ë‹¹ ìµœì†Œ 50ì¥ ì´ìƒ (ì´ 400ì¥+)\n4. **ë‹¤ì–‘ì„±**: ë‹¤ì–‘í•œ í–‰ì‚¬ ìœ í˜• ë° ìŠ¤íƒ€ì¼ í¬í•¨\n\n### ì´ë¯¸ì§€ ì—…ë¡œë“œ ë°©ë²•\n1. `samples/` í´ë”ì— ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë³µì‚¬í•©ë‹ˆë‹¤\n2. ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ train/val/testë¡œ ìë™ ë¶„í• í•©ë‹ˆë‹¤"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T12:57:00.908015Z",
     "start_time": "2025-11-25T12:57:00.901675Z"
    }
   },
   "source": "# ì´ë¯¸ì§€ í˜„í™© í™•ì¸ í•¨ìˆ˜\ndef check_images(directory: Path) -> dict:\n    \"\"\"ë””ë ‰í† ë¦¬ ë‚´ ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸\"\"\"\n    supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}\n    images = [f for f in directory.iterdir() if f.is_file() and f.suffix.lower() in supported_formats]\n    return {\n        'count': len(images),\n        'files': images,\n        'directory': directory\n    }\n\n# í˜„ì¬ ë°ì´í„°ì…‹ ìƒíƒœ í™•ì¸\nprint(\"ğŸ“Š í˜„ì¬ ë°ì´í„°ì…‹ ìƒíƒœ\")\nprint(\"=\" * 50)\n\nfor split_name, split_dir in [('samples', SAMPLES_DIR), ('train', TRAIN_IMAGES), ('val', VAL_IMAGES), ('test', TEST_IMAGES)]:\n    info = check_images(split_dir)\n    status = \"âœ“\" if info['count'] > 0 else \"âœ—\"\n    print(f\"{status} {split_name:8}: {info['count']:4}ì¥\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š í˜„ì¬ ë°ì´í„°ì…‹ ìƒíƒœ\n",
      "==================================================\n",
      "âœ“ samples :   10ì¥\n",
      "âœ“ train   :    8ì¥\n",
      "âœ“ val     :    1ì¥\n",
      "âœ“ test    :    1ì¥\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T12:57:07.819225Z",
     "start_time": "2025-11-25T12:57:07.812813Z"
    }
   },
   "source": [
    "# ë°ì´í„°ì…‹ ìë™ ë¶„í•  í•¨ìˆ˜\n",
    "def split_dataset(source_dir: Path, train_ratio=0.8, val_ratio=0.1, seed=42):\n",
    "    \"\"\"\n",
    "    samples í´ë”ì˜ ì´ë¯¸ì§€ë¥¼ train/val/testë¡œ ë¶„í• \n",
    "    \n",
    "    Args:\n",
    "        source_dir: ì›ë³¸ ì´ë¯¸ì§€ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬\n",
    "        train_ratio: í•™ìŠµ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ 80%)\n",
    "        val_ratio: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ 10%)\n",
    "        seed: ëœë¤ ì‹œë“œ\n",
    "    \"\"\"\n",
    "    supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}\n",
    "    all_images = [f for f in source_dir.iterdir() if f.is_file() and f.suffix.lower() in supported_formats]\n",
    "    \n",
    "    if len(all_images) == 0:\n",
    "        print(f\"âš ï¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {source_dir}\")\n",
    "        print(f\"   samples í´ë”ì— ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ë³µì‚¬í•˜ì„¸ìš”.\")\n",
    "        return\n",
    "    \n",
    "    random.seed(seed)\n",
    "    random.shuffle(all_images)\n",
    "    \n",
    "    n_total = len(all_images)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_val = int(n_total * val_ratio)\n",
    "    \n",
    "    train_imgs = all_images[:n_train]\n",
    "    val_imgs = all_images[n_train:n_train + n_val]\n",
    "    test_imgs = all_images[n_train + n_val:]\n",
    "    \n",
    "    # íŒŒì¼ ë³µì‚¬\n",
    "    for img in train_imgs:\n",
    "        shutil.copy(img, TRAIN_IMAGES / img.name)\n",
    "    for img in val_imgs:\n",
    "        shutil.copy(img, VAL_IMAGES / img.name)\n",
    "    for img in test_imgs:\n",
    "        shutil.copy(img, TEST_IMAGES / img.name)\n",
    "    \n",
    "    print(f\"âœ… ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ!\")\n",
    "    print(f\"   Train: {len(train_imgs)}ì¥\")\n",
    "    print(f\"   Val:   {len(val_imgs)}ì¥\")\n",
    "    print(f\"   Test:  {len(test_imgs)}ì¥\")\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¶„í•  ì‹¤í–‰ (samples í´ë”ì— ì´ë¯¸ì§€ê°€ ìˆì„ ë•Œ)\n",
    "# split_dataset(SAMPLES_DIR)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. ë¼ë²¨ë§ ê°€ì´ë“œ\n\n### YOLO ë¼ë²¨ í˜•ì‹\nê° ì´ë¯¸ì§€ì— ëŒ€ì‘í•˜ëŠ” `.txt` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n\n```\n<class_id> <x_center> <y_center> <width> <height>\n```\n\n- **class_id**: í´ë˜ìŠ¤ ë²ˆí˜¸ (0~7)\n- **x_center, y_center**: ë°”ìš´ë”© ë°•ìŠ¤ ì¤‘ì‹¬ ì¢Œí‘œ (0~1 ì •ê·œí™”)\n- **width, height**: ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° (0~1 ì •ê·œí™”)\n\n### ë¼ë²¨ë§ ë„êµ¬\n- **LabelImg**: ì˜¤í”ˆì†ŒìŠ¤, ë¡œì»¬ ì„¤ì¹˜ (`pip install labelImg`)\n- **Roboflow**: í´ë¼ìš°ë“œ ê¸°ë°˜, ìë™ ë¶„í•  (https://roboflow.com)\n- **CVAT**: í˜‘ì—… ê°€ëŠ¥, ê³ ê¸‰ ê¸°ëŠ¥ (https://www.cvat.ai)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T13:17:55.618824Z",
     "start_time": "2025-11-25T13:17:55.613884Z"
    }
   },
   "source": "# classes.txt íŒŒì¼ ìƒì„± (LabelImgìš©)\nclasses_file = CONFIGS_DIR / 'classes.txt'\nwith open(classes_file, 'w', encoding='utf-8') as f:\n    for name in CLASS_NAMES:\n        f.write(f\"{name}\\n\")\n\nprint(f\"âœ… í´ë˜ìŠ¤ íŒŒì¼ ìƒì„±: {classes_file}\")\nprint(\"\\níŒŒì¼ ë‚´ìš©:\")\nprint(\"-\" * 20)\nwith open(classes_file, 'r') as f:\n    print(f.read())",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í´ë˜ìŠ¤ íŒŒì¼ ìƒì„±: /Users/youeuncheol/PyCharmMiscProject/configs/classes.txt\n",
      "\n",
      "íŒŒì¼ ë‚´ìš©:\n",
      "--------------------\n",
      "booth\n",
      "stage\n",
      "exit\n",
      "entrance\n",
      "restroom\n",
      "food_area\n",
      "seating\n",
      "boundary\n",
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T13:58:04.116089Z",
     "start_time": "2025-11-25T13:58:04.099436Z"
    }
   },
   "source": "# LabelImg ì‹¤í–‰ í•¨ìˆ˜\ndef run_labelimg(image_dir: Path = None, save_dir: Path = None, classes_file: Path = None):\n    \"\"\"\n    LabelImg ë¼ë²¨ë§ ë„êµ¬ ì‹¤í–‰\n    \n    Args:\n        image_dir: ë¼ë²¨ë§í•  ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬\n        save_dir: ë¼ë²¨ ì €ì¥ ë””ë ‰í† ë¦¬\n        classes_file: í´ë˜ìŠ¤ ì •ì˜ íŒŒì¼ ê²½ë¡œ\n    \"\"\"\n    import subprocess\n    \n    # LabelImg CLI: labelImg [image_dir] [class_file] [save_dir]\n    cmd = ['labelImg']\n    \n    if image_dir:\n        cmd.append(str(image_dir))\n    if classes_file:  # ë‘ ë²ˆì§¸ ì¸ì: class_file\n        cmd.append(str(classes_file))\n    if save_dir:      # ì„¸ ë²ˆì§¸ ì¸ì: save_dir\n        cmd.append(str(save_dir))\n    \n    print(\"ğŸ·ï¸ LabelImg ì‹¤í–‰ ì¤‘...\")\n    print(f\"   ì´ë¯¸ì§€ í´ë”: {image_dir}\")\n    print(f\"   í´ë˜ìŠ¤ íŒŒì¼: {classes_file}\")\n    print(f\"   ë¼ë²¨ ì €ì¥: {save_dir}\")\n    print(\"\\nğŸ’¡ íŒ: YOLO í¬ë§·ìœ¼ë¡œ ì €ì¥í•˜ë ¤ë©´ View > Change Save Format > YOLO ì„ íƒ\")\n    \n    try:\n        subprocess.Popen(cmd)\n    except FileNotFoundError:\n        print(\"\\nâš ï¸ LabelImgê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n        print(\"   ì„¤ì¹˜: pip install labelImg\")\n\n# LabelImg ì‹¤í–‰ (í•™ìŠµ ì´ë¯¸ì§€ ë¼ë²¨ë§)\nrun_labelimg(TRAIN_IMAGES, TRAIN_LABELS, classes_file)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ·ï¸ LabelImg ì‹¤í–‰ ì¤‘...\n",
      "   ì´ë¯¸ì§€ í´ë”: /Users/youeuncheol/PyCharmMiscProject/data/images/train\n",
      "   í´ë˜ìŠ¤ íŒŒì¼: /Users/youeuncheol/PyCharmMiscProject/configs/classes.txt\n",
      "   ë¼ë²¨ ì €ì¥: /Users/youeuncheol/PyCharmMiscProject/data/labels/train\n",
      "\n",
      "ğŸ’¡ íŒ: YOLO í¬ë§·ìœ¼ë¡œ ì €ì¥í•˜ë ¤ë©´ View > Change Save Format > YOLO ì„ íƒ\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    # ë¼ë²¨ ê²€ì¦ í•¨ìˆ˜\n",
    "def validate_labels(labels_dir: Path, images_dir: Path):\n",
    "    \"\"\"ë¼ë²¨ íŒŒì¼ ê²€ì¦\"\"\"\n",
    "    supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}\n",
    "    \n",
    "    image_files = {f.stem for f in images_dir.iterdir() if f.suffix.lower() in supported_formats}\n",
    "    label_files = {f.stem for f in labels_dir.iterdir() if f.suffix == '.txt'}\n",
    "    \n",
    "    missing_labels = image_files - label_files\n",
    "    extra_labels = label_files - image_files\n",
    "    matched = image_files & label_files\n",
    "    \n",
    "    print(f\"ğŸ“Š ë¼ë²¨ ê²€ì¦ ê²°ê³¼\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"âœ“ ë§¤ì¹­ëœ ì´ë¯¸ì§€-ë¼ë²¨: {len(matched)}ê°œ\")\n",
    "    print(f\"âœ— ë¼ë²¨ ì—†ëŠ” ì´ë¯¸ì§€: {len(missing_labels)}ê°œ\")\n",
    "    print(f\"âœ— ì´ë¯¸ì§€ ì—†ëŠ” ë¼ë²¨: {len(extra_labels)}ê°œ\")\n",
    "    \n",
    "    if missing_labels:\n",
    "        print(f\"\\në¼ë²¨ ì—†ëŠ” ì´ë¯¸ì§€ ì˜ˆì‹œ: {list(missing_labels)[:5]}\")\n",
    "    \n",
    "    return {\n",
    "        'matched': len(matched),\n",
    "        'missing_labels': len(missing_labels),\n",
    "        'extra_labels': len(extra_labels)\n",
    "    }\n",
    "\n",
    "# ë¼ë²¨ ê²€ì¦ ì‹¤í–‰\n",
    "for split_name, (img_dir, lbl_dir) in [\n",
    "    ('train', (TRAIN_IMAGES, TRAIN_LABELS)),\n",
    "    ('val', (VAL_IMAGES, VAL_LABELS)),\n",
    "    ('test', (TEST_IMAGES, TEST_LABELS))\n",
    "]:\n",
    "    print(f\"\\n[{split_name}]\")\n",
    "    validate_labels(lbl_dir, img_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. ë°ì´í„°ì…‹ í†µê³„\n\në¼ë²¨ë§ëœ ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ë³„ ê°ì²´ ìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ë°ì´í„°ì…‹ í†µê³„ í•¨ìˆ˜\ndef dataset_statistics():\n    \"\"\"ë°ì´í„°ì…‹ ì´ë¯¸ì§€ ìˆ˜ ë° í´ë˜ìŠ¤ë³„ ê°ì²´ ìˆ˜ ì§‘ê³„\"\"\"\n    stats = {'train': {}, 'val': {}, 'test': {}}\n    class_counts = {split: {name: 0 for name in CLASS_NAMES} for split in stats.keys()}\n    \n    for split, (img_dir, lbl_dir) in [\n        ('train', (TRAIN_IMAGES, TRAIN_LABELS)),\n        ('val', (VAL_IMAGES, VAL_LABELS)),\n        ('test', (TEST_IMAGES, TEST_LABELS))\n    ]:\n        # ì´ë¯¸ì§€ ìˆ˜\n        supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}\n        images = [f for f in img_dir.iterdir() if f.is_file() and f.suffix.lower() in supported_formats]\n        stats[split]['images'] = len(images)\n        \n        # í´ë˜ìŠ¤ë³„ ê°ì²´ ìˆ˜\n        for lbl_file in lbl_dir.glob('*.txt'):\n            with open(lbl_file, 'r') as f:\n                for line in f:\n                    parts = line.strip().split()\n                    if len(parts) >= 5:\n                        class_id = int(parts[0])\n                        if 0 <= class_id < len(CLASS_NAMES):\n                            class_counts[split][CLASS_NAMES[class_id]] += 1\n    \n    # ê²°ê³¼ ì¶œë ¥\n    print(\"ğŸ“Š ë°ì´í„°ì…‹ í†µê³„\")\n    print(\"=\" * 60)\n    \n    # ì´ë¯¸ì§€ ìˆ˜\n    print(\"\\n[ì´ë¯¸ì§€ ìˆ˜]\")\n    for split, info in stats.items():\n        print(f\"  {split:6}: {info.get('images', 0):4}ì¥\")\n    \n    # í´ë˜ìŠ¤ë³„ ê°ì²´ ìˆ˜\n    print(\"\\n[í´ë˜ìŠ¤ë³„ ê°ì²´ ìˆ˜]\")\n    df = pd.DataFrame(class_counts).T\n    df['í•©ê³„'] = df.sum(axis=1)\n    print(df.to_string())\n    \n    # ì‹œê°í™”\n    total_counts = pd.Series({name: sum(class_counts[split][name] for split in stats.keys()) for name in CLASS_NAMES})\n    if total_counts.sum() > 0:\n        plt.figure(figsize=(12, 5))\n        colors = [f'#{r:02x}{g:02x}{b:02x}' for r, g, b in [CLASS_COLORS[name][::-1] for name in CLASS_NAMES]]\n        total_counts.plot(kind='bar', color=colors, edgecolor='black')\n        plt.xlabel('í´ë˜ìŠ¤')\n        plt.ylabel('ê°ì²´ ìˆ˜')\n        plt.title('í´ë˜ìŠ¤ë³„ ì´ ê°ì²´ ìˆ˜')\n        plt.xticks(rotation=45, ha='right')\n        plt.tight_layout()\n        plt.show()\n    \n    return stats, class_counts\n\n# í†µê³„ ì‹¤í–‰\nstats, class_counts = dataset_statistics()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 8. YOLOv8 ëª¨ë¸ í•™ìŠµ\n\n### ëª¨ë¸ í¬ê¸° ì„ íƒ ê°€ì´ë“œ\n\n| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | mAP | ì†ë„ | ê¶Œì¥ í™˜ê²½ |\n|------|----------|-----|------|-----------|\n| YOLOv8n | 3.2M | 37.3 | ë¹ ë¦„ | ì¼ë°˜ PC, ë¹ ë¥¸ í•™ìŠµ |\n| YOLOv8s | 11.2M | 44.9 | ì¤‘ê°„ | ê¶Œì¥ (ê· í˜•) |\n| YOLOv8m | 25.9M | 50.2 | ëŠë¦¼ | ê³ ì„±ëŠ¥ GPU |\n| YOLOv8l | 43.7M | 52.9 | ë§¤ìš° ëŠë¦¼ | ì„œë²„ê¸‰ GPU |\n\në¹ ë¥¸ ì‹¤ìŠµì„ ìœ„í•´ YOLOv8n(nano) ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ\nMODEL_NAME = 'yolov8n.pt'  # nano ëª¨ë¸ (ë¹ ë¥¸ í•™ìŠµìš©)\n# MODEL_NAME = 'yolov8s.pt'  # small ëª¨ë¸ (ê¶Œì¥)\n# MODEL_NAME = 'yolov8m.pt'  # medium ëª¨ë¸ (ê³ ì„±ëŠ¥)\n\nbase_model = YOLO(MODEL_NAME)\nprint(f\"âœ… ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ: {MODEL_NAME}\")\nprint(f\"   íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in base_model.model.parameters()):,}\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# í•™ìŠµ ì„¤ì •\nTRAIN_CONFIG = {\n    'data': str(CONFIGS_DIR / 'event_layout.yaml'),  # ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼\n    'epochs': 100,           # í•™ìŠµ ì—í­ ìˆ˜\n    'batch': 16,             # ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì ˆ)\n    'imgsz': 640,            # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°\n    'device': device,        # í•™ìŠµ ë””ë°”ì´ìŠ¤\n    'patience': 30,          # Early stopping patience\n    'save': True,            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n    'project': str(RESULTS_DIR),\n    'name': 'event_layout_train',\n    'exist_ok': True,\n    'pretrained': True,      # ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ ì‚¬ìš©\n    'optimizer': 'auto',     # ì˜µí‹°ë§ˆì´ì €\n    'lr0': 0.01,             # ì´ˆê¸° í•™ìŠµë¥ \n    'lrf': 0.01,             # ìµœì¢… í•™ìŠµë¥  ë¹„ìœ¨\n    'augment': True,         # ë°ì´í„° ì¦ê°•\n    'mosaic': 1.0,           # ëª¨ìì´í¬ ì¦ê°•\n    'fliplr': 0.5,           # ì¢Œìš° ë°˜ì „ í™•ë¥ \n    'flipud': 0.0,           # ìƒí•˜ ë°˜ì „ í™•ë¥ \n}\n\nprint(\"ğŸ“‹ í•™ìŠµ ì„¤ì •\")\nprint(\"=\" * 50)\nfor key, value in TRAIN_CONFIG.items():\n    print(f\"  {key}: {value}\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜\n",
    "def train_model():\n",
    "    \"\"\"YOLOv8 ëª¨ë¸ í•™ìŠµ ì‹¤í–‰\"\"\"\n",
    "    # ë°ì´í„° í™•ì¸\n",
    "    train_images = list(TRAIN_IMAGES.glob('*.*'))\n",
    "    train_labels = list(TRAIN_LABELS.glob('*.txt'))\n",
    "    \n",
    "    if len(train_images) == 0:\n",
    "        print(\"âš ï¸ í•™ìŠµ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(f\"   {TRAIN_IMAGES} í´ë”ì— ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.\")\n",
    "        return None\n",
    "    \n",
    "    if len(train_labels) == 0:\n",
    "        print(\"âš ï¸ í•™ìŠµ ë¼ë²¨ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(f\"   {TRAIN_LABELS} í´ë”ì— ë¼ë²¨ íŒŒì¼ì„ ì¶”ê°€í•˜ì„¸ìš”.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ğŸš€ í•™ìŠµ ì‹œì‘\")\n",
    "    print(f\"   ì´ë¯¸ì§€: {len(train_images)}ì¥\")\n",
    "    print(f\"   ë¼ë²¨: {len(train_labels)}ê°œ\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # ëª¨ë¸ í•™ìŠµ\n",
    "    model = YOLO(MODEL_NAME)\n",
    "    results = model.train(**TRAIN_CONFIG)\n",
    "    \n",
    "    print(\"\\nâœ… í•™ìŠµ ì™„ë£Œ!\")\n",
    "    print(f\"   ìµœì  ëª¨ë¸: {RESULTS_DIR / 'event_layout_train' / 'weights' / 'best.pt'}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# í•™ìŠµ ì‹¤í–‰ (ë°ì´í„°ê°€ ì¤€ë¹„ëœ í›„ ì£¼ì„ í•´ì œ)\n",
    "training_results = train_model()"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# í•™ìŠµ ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜\n",
    "def show_training_results():\n",
    "    \"\"\"í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„ ì‹œê°í™”\"\"\"\n",
    "    results_csv = RESULTS_DIR / 'event_layout_train' / 'results.csv'\n",
    "    \n",
    "    if not results_csv.exists():\n",
    "        print(\"âš ï¸ í•™ìŠµ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"   ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.read_csv(results_csv)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Loss ê·¸ë˜í”„\n",
    "    metrics = [\n",
    "        ('train/box_loss', 'val/box_loss', 'Box Loss'),\n",
    "        ('train/cls_loss', 'val/cls_loss', 'Class Loss'),\n",
    "        ('train/dfl_loss', 'val/dfl_loss', 'DFL Loss'),\n",
    "        ('metrics/precision(B)', None, 'Precision'),\n",
    "        ('metrics/recall(B)', None, 'Recall'),\n",
    "        ('metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'mAP'),\n",
    "    ]\n",
    "    \n",
    "    for idx, (col1, col2, title) in enumerate(metrics):\n",
    "        ax = axes[idx // 3, idx % 3]\n",
    "        if col1 in df.columns:\n",
    "            ax.plot(df['epoch'], df[col1], label='Train' if col2 else col1.split('/')[-1])\n",
    "        if col2 and col2 in df.columns:\n",
    "            ax.plot(df['epoch'], df[col2], label='Val' if 'val' in col2 else col2.split('/')[-1])\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ìµœì¢… ì„±ëŠ¥ ì¶œë ¥\n",
    "    if 'metrics/mAP50(B)' in df.columns:\n",
    "        print(f\"\\nğŸ“Š ìµœì¢… ì„±ëŠ¥ (ë§ˆì§€ë§‰ ì—í­)\")\n",
    "        print(f\"   mAP50: {df['metrics/mAP50(B)'].iloc[-1]:.4f}\")\n",
    "        if 'metrics/mAP50-95(B)' in df.columns:\n",
    "            print(f\"   mAP50-95: {df['metrics/mAP50-95(B)'].iloc[-1]:.4f}\")\n",
    "\n",
    "# í•™ìŠµ ê²°ê³¼ ì‹œê°í™” (í•™ìŠµ ì™„ë£Œ í›„ ì‹¤í–‰)\n",
    "show_training_results()"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 9. ëª¨ë¸ ê²€ì¦\n\ní•™ìŠµëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê²€ì¦ ë°ì´í„°ì…‹ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ\nbest_model_path = RESULTS_DIR / 'event_layout_train' / 'weights' / 'best.pt'\n\nif best_model_path.exists():\n    model = YOLO(str(best_model_path))\n    print(f\"âœ… í•™ìŠµëœ ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ\")\n    print(f\"   ê²½ë¡œ: {best_model_path}\")\nelse:\n    model = YOLO('yolov8n.pt')\n    print(\"âš ï¸ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ì–´ ì‚¬ì „í•™ìŠµ ëª¨ë¸(COCO)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n    print(\"   ì»¤ìŠ¤í…€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë¨¼ì € í•™ìŠµì„ ì§„í–‰í•˜ì„¸ìš”.\")\n\n# ëª¨ë¸ ì •ë³´ ì¶œë ¥\nprint(f\"\\nğŸ“Š ëª¨ë¸ ì •ë³´\")\nprint(f\"   í´ë˜ìŠ¤ ìˆ˜: {len(model.names)}\")\nprint(f\"   í´ë˜ìŠ¤: {list(model.names.values())[:8]}...\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# ëª¨ë¸ ê²€ì¦ í•¨ìˆ˜\n",
    "def evaluate_model(model, data_yaml: str):\n",
    "    \"\"\"ê²€ì¦ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\"\"\"\n",
    "    print(\"ğŸ” ëª¨ë¸ ê²€ì¦ ì¤‘...\")\n",
    "    \n",
    "    results = model.val(\n",
    "        data=data_yaml,\n",
    "        split='val',\n",
    "        batch=16,\n",
    "        imgsz=640,\n",
    "        device=device,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    print(\"\\nğŸ“Š ê²€ì¦ ê²°ê³¼\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Precision: {results.results_dict['metrics/precision(B)']:.4f}\")\n",
    "    print(f\"Recall:    {results.results_dict['metrics/recall(B)']:.4f}\")\n",
    "    print(f\"mAP50:     {results.results_dict['metrics/mAP50(B)']:.4f}\")\n",
    "    print(f\"mAP50-95:  {results.results_dict['metrics/mAP50-95(B)']:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ëª¨ë¸ ê²€ì¦ ì‹¤í–‰ (ì»¤ìŠ¤í…€ ëª¨ë¸ì´ ìˆì„ ë•Œ)\n",
    "# val_results = evaluate_model(model, str(CONFIGS_DIR / 'event_layout.yaml'))"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 10. ìƒˆë¡œìš´ ë°°ì¹˜ë„ ì¶”ë¡ \n\ní•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ í–‰ì‚¬ ë°°ì¹˜ë„ ì´ë¯¸ì§€ì—ì„œ ê°ì²´ë¥¼ ì¸ì‹í•©ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡  í•¨ìˆ˜ (í†µë¡œ ìë™ ê³„ì‚° í¬í•¨)\ndef predict_single_image(model, image_path: str, conf_threshold: float = 0.25, show_pathway: bool = True):\n    \"\"\"\n    ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ê°ì²´ ì¸ì‹ ìˆ˜í–‰ ë° í†µë¡œ ìë™ ê³„ì‚°\n    \n    Args:\n        model: YOLO ëª¨ë¸\n        image_path: ì´ë¯¸ì§€ ê²½ë¡œ\n        conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’\n        show_pathway: í†µë¡œ ì‹œê°í™” ì—¬ë¶€\n    \n    Returns:\n        ì¸ì‹ëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸\n    \"\"\"\n    results = model.predict(\n        source=image_path,\n        conf=conf_threshold,\n        iou=0.45,\n        imgsz=640,\n        device=device,\n        verbose=False\n    )\n    \n    result = results[0]\n    img_with_boxes = result.plot()\n    \n    # ì¸ì‹ëœ ê°ì²´ ì •ë³´ ìˆ˜ì§‘\n    detected_objects = []\n    for idx, box in enumerate(result.boxes):\n        class_id = int(box.cls[0])\n        confidence = float(box.conf[0])\n        class_name = model.names[class_id]\n        bbox = box.xyxy[0].cpu().numpy()\n        \n        obj_info = {\n            'id': idx + 1,\n            'class': class_name,\n            'class_kr': CLASS_NAMES_KR.get(class_name, class_name),\n            'confidence': confidence,\n            'bbox': bbox.tolist(),\n        }\n        detected_objects.append(obj_info)\n    \n    # í†µë¡œ ìë™ ê³„ì‚° ë° ì‹œê°í™”\n    pathway_ratio = 0.0\n    if show_pathway and detected_objects:\n        img_with_pathway, pathway_ratio, pathway_mask = calculate_and_visualize_pathway(\n            img_with_boxes, detected_objects\n        )\n        display_img = img_with_pathway\n    else:\n        display_img = img_with_boxes\n    \n    # ì‹œê°í™”\n    plt.figure(figsize=(14, 10))\n    plt.imshow(cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    title = f'ê°ì²´ ì¸ì‹ ê²°ê³¼ (ì‹ ë¢°ë„ >= {conf_threshold:.0%})'\n    if show_pathway:\n        title += f' | í†µë¡œ ë©´ì : {pathway_ratio:.1%}'\n    plt.title(title, fontsize=14)\n    plt.tight_layout()\n    plt.show()\n    \n    # ì¸ì‹ëœ ê°ì²´ ì •ë³´ ì¶œë ¥\n    print(\"\\nğŸ“¦ ì¸ì‹ëœ ê°ì²´\")\n    print(\"=\" * 60)\n    \n    for obj in detected_objects:\n        print(f\"{obj['id']}. {obj['class_kr']} ({obj['class']})\")\n        print(f\"   ì‹ ë¢°ë„: {obj['confidence']:.2%}\")\n        bbox = obj['bbox']\n        print(f\"   ì¢Œí‘œ: ({bbox[0]:.0f}, {bbox[1]:.0f}) ~ ({bbox[2]:.0f}, {bbox[3]:.0f})\")\n    \n    print(f\"\\nì´ {len(detected_objects)}ê°œ ê°ì²´ ì¸ì‹ë¨\")\n    if show_pathway:\n        print(f\"ğŸ“Š í†µë¡œ ë©´ì : {pathway_ratio:.1%} (boundary ëŒ€ë¹„)\")\n    \n    return detected_objects\n\n# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ ì¶”ë¡  ì‹¤í–‰\ntest_images = list(TEST_IMAGES.glob('*.*'))\nif test_images:\n    detected = predict_single_image(model, str(test_images[0]))\nelse:\n    print(\"âš ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n    print(f\"   {TEST_IMAGES} í´ë”ì— ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.\")\n    detected = []",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# í†µë¡œ ìë™ ê³„ì‚° ë° ì‹œê°í™” í•¨ìˆ˜\ndef calculate_and_visualize_pathway(image: np.ndarray, detected_objects: list) -> tuple:\n    \"\"\"\n    boundary ë‚´ë¶€ì—ì„œ ë‹¤ë¥¸ ê°ì²´ë¥¼ ì œì™¸í•œ ì˜ì—­ì„ í†µë¡œë¡œ ê³„ì‚°í•˜ê³  ì‹œê°í™”\n\n    Args:\n        image: ì›ë³¸ ì´ë¯¸ì§€ (numpy array, BGR)\n        detected_objects: ì¸ì‹ëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸\n\n    Returns:\n        result_image: í†µë¡œê°€ ì˜¤ë²„ë ˆì´ëœ ì´ë¯¸ì§€\n        pathway_ratio: í†µë¡œ ë©´ì  ë¹„ìœ¨ (boundary ëŒ€ë¹„)\n        pathway_mask: í†µë¡œ ë§ˆìŠ¤í¬ (numpy array)\n    \"\"\"\n    h, w = image.shape[:2]\n\n    # boundary ì°¾ê¸°\n    boundary_bbox = None\n    for obj in detected_objects:\n        if obj['class'] == 'boundary':\n            boundary_bbox = obj['bbox']\n            break\n\n    if boundary_bbox is None:\n        print(\"âš ï¸ boundaryê°€ ê°ì§€ë˜ì§€ ì•Šì•„ í†µë¡œë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n        return image, 0.0, None\n\n    # boundary ë§ˆìŠ¤í¬ ìƒì„±\n    x1, y1, x2, y2 = map(int, boundary_bbox)\n    boundary_mask = np.zeros((h, w), dtype=np.uint8)\n    boundary_mask[y1:y2, x1:x2] = 255\n\n    # ê°ì²´ ë§ˆìŠ¤í¬ ìƒì„± (0~6 í´ë˜ìŠ¤: booth, stage, exit, entrance, restroom, food_area, seating)\n    objects_mask = np.zeros((h, w), dtype=np.uint8)\n    object_classes = ['booth', 'stage', 'exit', 'entrance', 'restroom', 'food_area', 'seating']\n\n    for obj in detected_objects:\n        if obj['class'] in object_classes:\n            ox1, oy1, ox2, oy2 = map(int, obj['bbox'])\n            objects_mask[oy1:oy2, ox1:ox2] = 255\n\n    # í†µë¡œ ë§ˆìŠ¤í¬ = boundary - ê°ì²´ë“¤\n    pathway_mask = cv2.bitwise_and(boundary_mask, cv2.bitwise_not(objects_mask))\n\n    # í†µë¡œ ë©´ì  ë¹„ìœ¨ ê³„ì‚°\n    boundary_area = np.sum(boundary_mask > 0)\n    pathway_area = np.sum(pathway_mask > 0)\n    pathway_ratio = pathway_area / boundary_area if boundary_area > 0 else 0.0\n\n    # ì‹œê°í™”: í†µë¡œ ì˜ì—­ì„ íŒŒë€ìƒ‰ ë°˜íˆ¬ëª…ìœ¼ë¡œ ì˜¤ë²„ë ˆì´\n    result_image = image.copy()\n    overlay = result_image.copy()\n    overlay[pathway_mask > 0] = PATHWAY_COLOR  # íŒŒë€ìƒ‰ (BGR)\n    alpha = 0.3\n    result_image = cv2.addWeighted(overlay, alpha, result_image, 1 - alpha, 0)\n\n    print(f\"ğŸ“Š í†µë¡œ ë©´ì  ë¹„ìœ¨: {pathway_ratio:.1%} (boundary ëŒ€ë¹„)\")\n\n    return result_image, pathway_ratio, pathway_mask\n\n\n# í†µë¡œ ì‹œê°í™” í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\ndef visualize_pathway_only(image_path: str, detected_objects: list):\n    \"\"\"í†µë¡œë§Œ ë³„ë„ë¡œ ì‹œê°í™”\"\"\"\n    img = cv2.imread(image_path)\n    if img is None:\n        print(f\"âš ï¸ ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}\")\n        return\n    \n    pathway_img, ratio, mask = calculate_and_visualize_pathway(img, detected_objects)\n    \n    if mask is None:\n        return\n    \n    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n    \n    # ì›ë³¸ ì´ë¯¸ì§€\n    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    axes[0].set_title('ì›ë³¸ ì´ë¯¸ì§€')\n    axes[0].axis('off')\n    \n    # í†µë¡œ ë§ˆìŠ¤í¬\n    axes[1].imshow(mask, cmap='Blues')\n    axes[1].set_title(f'í†µë¡œ ì˜ì—­ ë§ˆìŠ¤í¬ (ë©´ì : {ratio:.1%})')\n    axes[1].axis('off')\n    \n    # í†µë¡œ ì˜¤ë²„ë ˆì´\n    axes[2].imshow(cv2.cvtColor(pathway_img, cv2.COLOR_BGR2RGB))\n    axes[2].set_title('í†µë¡œ ì˜¤ë²„ë ˆì´')\n    axes[2].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\nprint(\"âœ… í†µë¡œ ê³„ì‚° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ì¼ê´„ ì¶”ë¡  í•¨ìˆ˜\ndef predict_batch(model, image_dir: Path, conf_threshold: float = 0.25):\n    \"\"\"ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¼ê´„ ì¶”ë¡ \"\"\"\n    supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}\n    images = [f for f in image_dir.iterdir() if f.suffix.lower() in supported_formats]\n    \n    if not images:\n        print(f\"âš ï¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {image_dir}\")\n        return None\n    \n    print(f\"ğŸ” {len(images)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘...\")\n    \n    results = model.predict(\n        source=str(image_dir),\n        conf=conf_threshold,\n        iou=0.45,\n        imgsz=640,\n        device=device,\n        save=True,\n        project=str(RESULTS_DIR),\n        name='inference_results',\n        exist_ok=True,\n        verbose=False\n    )\n    \n    # í†µê³„ ìˆ˜ì§‘\n    all_stats = []\n    for idx, result in enumerate(results):\n        class_counts = {name: 0 for name in CLASS_NAMES}\n        for box in result.boxes:\n            class_name = model.names[int(box.cls[0])]\n            if class_name in class_counts:\n                class_counts[class_name] += 1\n        \n        stats = {'image': Path(result.path).name, 'total': len(result.boxes)}\n        stats.update(class_counts)\n        all_stats.append(stats)\n    \n    df = pd.DataFrame(all_stats)\n    \n    print(f\"\\nâœ… ì²˜ë¦¬ ì™„ë£Œ!\")\n    print(f\"   ê²°ê³¼ ì €ì¥: {RESULTS_DIR / 'inference_results'}\")\n    print(\"\\nğŸ“Š ì´ë¯¸ì§€ë³„ ì¸ì‹ ê²°ê³¼\")\n    print(df.to_string(index=False))\n    \n    return df\n\n# ì¼ê´„ ì¶”ë¡  ì‹¤í–‰\n# batch_results = predict_batch(model, TEST_IMAGES)",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 11. ê²°ê³¼ ì‹œê°í™”\n\në‹¤ì–‘í•œ ì‹ ë¢°ë„ ì„ê³„ê°’ê³¼ í´ë˜ìŠ¤ í•„í„°ë§ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ì‹ ë¢°ë„ ì„ê³„ê°’ ë¹„êµ í•¨ìˆ˜\ndef compare_confidence_thresholds(model, image_path: str, thresholds=[0.1, 0.25, 0.5, 0.75]):\n    \"\"\"ë‹¤ì–‘í•œ ì‹ ë¢°ë„ ì„ê³„ê°’ìœ¼ë¡œ ê²°ê³¼ ë¹„êµ\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    axes = axes.flatten()\n    \n    for idx, conf in enumerate(thresholds):\n        results = model.predict(\n            source=image_path,\n            conf=conf,\n            imgsz=640,\n            device=device,\n            verbose=False\n        )\n        \n        img = results[0].plot()\n        \n        axes[idx].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n        axes[idx].axis('off')\n        axes[idx].set_title(f'ì‹ ë¢°ë„ >= {conf:.0%} ({len(results[0].boxes)}ê°œ ê°ì²´)', fontsize=12)\n    \n    plt.tight_layout()\n    plt.show()\n\n# ì‹ ë¢°ë„ ë¹„êµ ì‹¤í–‰\nif test_images:\n    compare_confidence_thresholds(model, str(test_images[0]))",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# íŠ¹ì • í´ë˜ìŠ¤ í•„í„°ë§ ì‹œê°í™”\ndef visualize_by_class(model, image_path: str, target_classes: list):\n    \"\"\"íŠ¹ì • í´ë˜ìŠ¤ë§Œ í•„í„°ë§í•˜ì—¬ ì‹œê°í™”\"\"\"\n    target_ids = [idx for idx, name in model.names.items() if name in target_classes]\n    \n    if not target_ids:\n        print(f\"âš ï¸ í•´ë‹¹ í´ë˜ìŠ¤ê°€ ëª¨ë¸ì— ì—†ìŠµë‹ˆë‹¤: {target_classes}\")\n        return\n    \n    results = model.predict(\n        source=image_path,\n        conf=0.25,\n        imgsz=640,\n        device=device,\n        classes=target_ids,\n        verbose=False\n    )\n    \n    img = results[0].plot()\n    \n    plt.figure(figsize=(14, 10))\n    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    target_kr = [CLASS_NAMES_KR.get(c, c) for c in target_classes]\n    plt.title(f'í•„í„°ë§: {target_kr} ({len(results[0].boxes)}ê°œ)', fontsize=14)\n    plt.tight_layout()\n    plt.show()\n\n# ì•ˆì „ ê´€ë ¨ í´ë˜ìŠ¤ë§Œ ì‹œê°í™” (ì˜ˆ: ì¶œêµ¬, ì…êµ¬, í†µë¡œ)\n# if test_images:\n#     visualize_by_class(model, str(test_images[0]), ['exit', 'entrance', 'pathway'])",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 12. í–‰ì‚¬ ì•ˆì „ ë¶„ì„\n\nì¸ì‹ëœ ê°ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í–‰ì‚¬ ì•ˆì „ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n\n### ì•ˆì „ ê¸°ì¤€ (festival_safety_AI_solution_guide.md ì°¸ì¡°)\n- **ì£¼ í”¼ë‚œí†µë¡œ**: ìµœì†Œ 3m í­\n- **ë³´ì¡° í”¼ë‚œí†µë¡œ**: ìµœì†Œ 1.5m í­\n- **ìµœëŒ€ ëŒ€í”¼ ê±°ë¦¬**: 100m\n- **ì¶œêµ¬ í­**: 100ëª…ë‹¹ 0.6m\n- **ë°€ì§‘ë„ ìœ„í—˜ ê¸°ì¤€**: 3.0ëª…/ã¡ ì´ìƒ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ì•ˆì „ ë¶„ì„ í•¨ìˆ˜ (í†µë¡œëŠ” ìë™ ê³„ì‚°ë˜ë¯€ë¡œ ì œì™¸)\ndef analyze_safety(detected_objects: list, expected_visitors: int = 1000):\n    \"\"\"\n    ì¸ì‹ëœ ê°ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í–‰ì‚¬ ì•ˆì „ ë¶„ì„\n    \n    Args:\n        detected_objects: ì¸ì‹ëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸\n        expected_visitors: ì˜ˆìƒ ë°©ë¬¸ì ìˆ˜\n    \n    Returns:\n        ì•ˆì „ ë¶„ì„ ê²°ê³¼\n    \n    Note:\n        í†µë¡œëŠ” boundary ë‚´ë¶€ì—ì„œ ìë™ ê³„ì‚°ë˜ë¯€ë¡œ ë³„ë„ í´ë˜ìŠ¤ë¡œ ì¸ì‹í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n    \"\"\"\n    analysis = {\n        'summary': {},\n        'warnings': [],\n        'recommendations': [],\n        'score': 100,\n    }\n    \n    # í´ë˜ìŠ¤ë³„ ì§‘ê³„\n    class_counts = {name: 0 for name in CLASS_NAMES}\n    for obj in detected_objects:\n        class_name = obj.get('class', '')\n        if class_name in class_counts:\n            class_counts[class_name] += 1\n    \n    analysis['summary'] = class_counts\n    \n    # ì¶œêµ¬ ê²€ì‚¬\n    if class_counts['exit'] == 0:\n        analysis['warnings'].append({\n            'level': 'CRITICAL',\n            'message': 'ì¶œêµ¬ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¹„ìƒêµ¬ í™•ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.'\n        })\n        analysis['score'] -= 30\n    elif class_counts['exit'] < 2:\n        analysis['warnings'].append({\n            'level': 'HIGH',\n            'message': f\"ì¶œêµ¬ê°€ {class_counts['exit']}ê°œë¡œ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ 2ê°œ ì´ìƒ ê¶Œì¥.\"\n        })\n        analysis['score'] -= 15\n    \n    # ì…êµ¬ ê²€ì‚¬\n    if class_counts['entrance'] == 0:\n        analysis['warnings'].append({\n            'level': 'MEDIUM',\n            'message': 'ì…êµ¬ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'\n        })\n        analysis['score'] -= 10\n    \n    # boundary ê²€ì‚¬ (í†µë¡œ ìë™ ê³„ì‚°ì„ ìœ„í•´ í•„ìš”)\n    if class_counts['boundary'] == 0:\n        analysis['warnings'].append({\n            'level': 'MEDIUM',\n            'message': 'boundaryê°€ ê°ì§€ë˜ì§€ ì•Šì•„ í†µë¡œ ì˜ì—­ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'\n        })\n        analysis['score'] -= 10\n    \n    # ì•ˆì „ì‹œì„¤ ê¶Œì¥\n    if class_counts['exit'] > 0:\n        required_exit_width = (expected_visitors / 100) * 0.6\n        analysis['recommendations'].append(\n            f\"ì˜ˆìƒ ë°©ë¬¸ì {expected_visitors}ëª… ê¸°ì¤€, ì´ ì¶œêµ¬ í­ {required_exit_width:.1f}m ì´ìƒ í•„ìš”\"\n        )\n    \n    # ì ìˆ˜ ë³´ì •\n    analysis['score'] = max(0, analysis['score'])\n    \n    # ìƒíƒœ ê²°ì •\n    if analysis['score'] >= 80:\n        analysis['status'] = 'PASS'\n        analysis['status_kr'] = 'ì–‘í˜¸'\n    elif analysis['score'] >= 50:\n        analysis['status'] = 'WARNING'\n        analysis['status_kr'] = 'ì£¼ì˜'\n    else:\n        analysis['status'] = 'CRITICAL'\n        analysis['status_kr'] = 'ìœ„í—˜'\n    \n    return analysis",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# ì•ˆì „ ë¦¬í¬íŠ¸ ì¶œë ¥ í•¨ìˆ˜\ndef print_safety_report(analysis: dict):\n    \"\"\"ì•ˆì „ ë¶„ì„ ë¦¬í¬íŠ¸ ì¶œë ¥\"\"\"\n    print(\"=\" * 60)\n    print(\"ğŸ›¡ï¸ í–‰ì‚¬ ë°°ì¹˜ë„ ì•ˆì „ ë¶„ì„ ë¦¬í¬íŠ¸\")\n    print(\"=\" * 60)\n    \n    # ì¢…í•© ìƒíƒœ\n    status_emoji = {'PASS': 'âœ…', 'WARNING': 'âš ï¸', 'CRITICAL': 'ğŸš¨'}\n    print(f\"\\nì¢…í•© ìƒíƒœ: {status_emoji.get(analysis['status'], 'â“')} {analysis['status_kr']}\")\n    print(f\"ì•ˆì „ ì ìˆ˜: {analysis['score']}/100ì \")\n    \n    # ì¸ì‹ëœ ê°ì²´ ìš”ì•½\n    print(\"\\nğŸ“¦ ì¸ì‹ëœ ê°ì²´ ìš”ì•½\")\n    print(\"-\" * 40)\n    for name, count in analysis['summary'].items():\n        if count > 0:\n            print(f\"  {CLASS_NAMES_KR.get(name, name):8}: {count}ê°œ\")\n    \n    # ê²½ê³  ì‚¬í•­\n    if analysis['warnings']:\n        print(\"\\nâš ï¸ ê²½ê³  ì‚¬í•­\")\n        print(\"-\" * 40)\n        for w in analysis['warnings']:\n            level_emoji = {'CRITICAL': 'ğŸš¨', 'HIGH': 'ğŸ”´', 'MEDIUM': 'ğŸŸ¡', 'LOW': 'ğŸŸ¢'}\n            print(f\"  {level_emoji.get(w['level'], 'â€¢')} [{w['level']}] {w['message']}\")\n    \n    # ê¶Œì¥ ì‚¬í•­\n    if analysis['recommendations']:\n        print(\"\\nğŸ’¡ ê¶Œì¥ ì‚¬í•­\")\n        print(\"-\" * 40)\n        for r in analysis['recommendations']:\n            print(f\"  â€¢ {r}\")\n    \n    print(\"\\n\" + \"=\" * 60)\n\n# ì•ˆì „ ë¶„ì„ ì‹¤í–‰\nif detected:\n    safety_analysis = analyze_safety(detected, expected_visitors=1000)\n    print_safety_report(safety_analysis)\nelse:\n    print(\"âš ï¸ ì¸ì‹ëœ ê°ì²´ê°€ ì—†ì–´ ì•ˆì „ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n    safety_analysis = None",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 13. ê²°ê³¼ ë‚´ë³´ë‚´ê¸°\n\në¶„ì„ ê²°ê³¼ë¥¼ JSON, CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# JSON ë‚´ë³´ë‚´ê¸° í•¨ìˆ˜\ndef export_to_json(detected_objects: list, safety_analysis: dict, output_path: Path):\n    \"\"\"ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n    export_data = {\n        'timestamp': datetime.now().isoformat(),\n        'detected_objects': detected_objects,\n        'safety_analysis': safety_analysis,\n    }\n    \n    with open(output_path, 'w', encoding='utf-8') as f:\n        json.dump(export_data, f, ensure_ascii=False, indent=2)\n    \n    print(f\"âœ… JSON ì €ì¥ ì™„ë£Œ: {output_path}\")\n\n# CSV ë‚´ë³´ë‚´ê¸° í•¨ìˆ˜\ndef export_to_csv(detected_objects: list, output_path: Path):\n    \"\"\"ì¸ì‹ëœ ê°ì²´ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥\"\"\"\n    df = pd.DataFrame(detected_objects)\n    \n    if 'bbox' in df.columns:\n        df['x1'] = df['bbox'].apply(lambda x: x[0] if x else None)\n        df['y1'] = df['bbox'].apply(lambda x: x[1] if x else None)\n        df['x2'] = df['bbox'].apply(lambda x: x[2] if x else None)\n        df['y2'] = df['bbox'].apply(lambda x: x[3] if x else None)\n        df = df.drop('bbox', axis=1)\n    \n    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n    print(f\"âœ… CSV ì €ì¥ ì™„ë£Œ: {output_path}\")\n\n# ê²°ê³¼ ë‚´ë³´ë‚´ê¸° ì‹¤í–‰\nif detected and safety_analysis:\n    export_to_json(detected, safety_analysis, RESULTS_DIR / 'analysis_result.json')\n    export_to_csv(detected, RESULTS_DIR / 'detected_objects.csv')",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 14. ëª¨ë¸ ë‚´ë³´ë‚´ê¸°\n\ní•™ìŠµëœ ëª¨ë¸ì„ ë‹¤ë¥¸ í˜•ì‹(ONNX)ìœ¼ë¡œ ë‚´ë³´ë‚´ ë°°í¬ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ONNX ëª¨ë¸ ë‚´ë³´ë‚´ê¸° í•¨ìˆ˜\ndef export_to_onnx(model_path: Path):\n    \"\"\"í•™ìŠµëœ ëª¨ë¸ì„ ONNX í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°\"\"\"\n    if not model_path.exists():\n        print(f\"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}\")\n        return None\n    \n    model = YOLO(str(model_path))\n    \n    print(\"ğŸ“¦ ONNX ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì¤‘...\")\n    onnx_path = model.export(\n        format='onnx',\n        imgsz=640,\n        simplify=True,\n        dynamic=False\n    )\n    \n    print(f\"âœ… ONNX ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {onnx_path}\")\n    return onnx_path\n\n# ONNX ë‚´ë³´ë‚´ê¸° ì‹¤í–‰ (í•™ìŠµëœ ëª¨ë¸ì´ ìˆì„ ë•Œ)\n# if best_model_path.exists():\n#     export_to_onnx(best_model_path)",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 15. ì •ë¦¬ ë° ë‹¤ìŒ ë‹¨ê³„\n\n### í•™ìŠµ ë‚´ìš© ìš”ì•½\n1. âœ… YOLOv8 í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜\n2. âœ… í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±\n3. âœ… í–‰ì‚¬ ë°°ì¹˜ë„ ì „ìš© 8ê°œ í´ë˜ìŠ¤ ì •ì˜\n4. âœ… ë°ì´í„° ì¤€ë¹„ ë° ë¼ë²¨ë§ (LabelImg)\n5. âœ… YOLOv8 ì»¤ìŠ¤í…€ ëª¨ë¸ í•™ìŠµ\n6. âœ… ëª¨ë¸ ê²€ì¦ ë° ì„±ëŠ¥ í‰ê°€\n7. âœ… ìƒˆë¡œìš´ ì´ë¯¸ì§€ ì¶”ë¡ \n8. âœ… ê²°ê³¼ ì‹œê°í™”\n9. âœ… í–‰ì‚¬ ì•ˆì „ ë¶„ì„\n10. âœ… ê²°ê³¼ ë‚´ë³´ë‚´ê¸° (JSON, CSV, ONNX)\n\n### ë‹¤ìŒ ë‹¨ê³„\n- [ ] ë” ë§ì€ ë°°ì¹˜ë„ ì´ë¯¸ì§€ ìˆ˜ì§‘ (ëª©í‘œ: 100ì¥+)\n- [ ] ë¼ë²¨ë§ ì™„ë£Œ ë° ëª¨ë¸ ì¬í•™ìŠµ\n- [ ] í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìœ¼ë¡œ ì„±ëŠ¥ ê°œì„ \n- [ ] Streamlit ì›¹ ì•± ê°œë°œ\n- [ ] FastAPI ì„œë²„ êµ¬ì¶•\n- [ ] ì‹¤ì‹œê°„ ë¶„ì„ ì‹œìŠ¤í…œ êµ¬í˜„\n\n### ì°¸ê³  ìë£Œ\n- [YOLOv8 ê³µì‹ ë¬¸ì„œ](https://docs.ultralytics.com)\n- [LabelImg GitHub](https://github.com/tzutalin/labelImg)\n- [í–‰ì‚¬ ì•ˆì „ ê´€ë¦¬ ê°€ì´ë“œ](festival_safety_AI_solution_guide.md)\n\n---\n**ë…¸íŠ¸ë¶ ì‘ì„±ì¼**: 2025-11-25  \n**ë²„ì „**: 1.0.0",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
